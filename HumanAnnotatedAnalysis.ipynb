{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "negationLex=[\"ain't\", \"cannot\", \"cant\", \"daren't\", \"didn't\", \"doesn't\", \"don't\", \"hadn't\", \"hardly\", \"hasn't\", \"haven't\", \"havn't\", \"isn't\", \"lack\", \"lacking\", \"lacks\", \"neither\", \"never\", \"no\", \"nobody\", \"none\", \"nor\", \"not\", \"nothing\", \"nowhere\",\"mightnt\", \"mustn't\", \"needn't\", \"oughtn't\", \"shan't\",\"shouldn't\", \"wasn't\", \"without\", \"wouldnt\", \"n't\"]\n",
    "\n",
    "neg_dic = {}\n",
    "aff_dic = {}\n",
    "for neg in negationLex:\n",
    "    neg_dic[neg] = 0\n",
    "    aff_dic[neg] = 0   \n",
    "lines = []\n",
    "with open('negationSamplesAll.txt') as fp:  \n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        lines.append(line)\n",
    "        if '\\tNegative\\n' in line:\n",
    "            for neg in negationLex:\n",
    "                if neg in line:\n",
    "                    neg_dic[neg] = neg_dic[neg] + 1\n",
    "        if '\\tAffirmative\\n' in line:\n",
    "            for neg in negationLex:\n",
    "                if neg in line:\n",
    "                    aff_dic[neg] = aff_dic[neg] + 1\n",
    "        line = fp.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"ain't\": 0.0,\n",
       " 'cannot': 0.0,\n",
       " 'cant': 0.0,\n",
       " \"daren't\": 0.0,\n",
       " \"didn't\": 0.0,\n",
       " \"doesn't\": 0.0,\n",
       " \"don't\": 0.0,\n",
       " \"hadn't\": 0.0,\n",
       " 'hardly': 0.0,\n",
       " \"hasn't\": 0.0,\n",
       " \"haven't\": 0.0,\n",
       " \"havn't\": 0.0,\n",
       " \"isn't\": 0.0,\n",
       " 'lack': 0.0,\n",
       " 'lacking': 0.0,\n",
       " 'lacks': 0.0,\n",
       " 'mightnt': 0.0,\n",
       " \"mustn't\": 0.0,\n",
       " \"n't\": 0.0,\n",
       " \"needn't\": 0.0,\n",
       " 'neither': 0.0,\n",
       " 'never': 0.0,\n",
       " 'no': 0.07801418439716312,\n",
       " 'nobody': 0.0,\n",
       " 'none': 0.0,\n",
       " 'nor': 0.0,\n",
       " 'not': 0.08333333333333333,\n",
       " 'nothing': 0.0,\n",
       " 'nowhere': 0.0,\n",
       " \"oughtn't\": 0.0,\n",
       " \"shan't\": 0.0,\n",
       " \"shouldn't\": 0.0,\n",
       " \"wasn't\": 0.0,\n",
       " 'without': 0.0,\n",
       " 'wouldnt': 0.0}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {}\n",
    "for neg in negationLex:\n",
    "    if float(aff_dic[neg]) != 0:\n",
    "        dic[neg] = float(neg_dic[neg])/float(aff_dic[neg])\n",
    "    else:\n",
    "        dic[neg] = 0.0\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.parsing.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "aff_dic = {}\n",
    "neg_dic = {}\n",
    "non_dic = {}\n",
    "\n",
    "positiveLex = ['activate', 'activation', 'activator', 'stimulatory', 'stimulation', 'stimulate', 'increase','increased']\n",
    "cosPosLex = ['activated','stimulated','activates','elevation','-stimulated','increases','up-regulation','activators','upregulate','enhanced','enhancement','stimulating','stimulator','elevate','augments','trigger','upregulates','inducer','up-regulated','augmented']\n",
    "negativeLex = ['inhibit', 'inhibitors', 'inhibitor', 'inhibition', 'repress', 'repression', 'repressor', 'block']\n",
    "cosNegLex = ['inhibiting', 'blocking', 'inhibitory', 'blocked', 'down-regulation','downregulation','inactivate','suppress','suppression','antagonism','antagonists','blockers','represses','blockage','inactivated','decline']\n",
    "\n",
    "stemPosLex = []\n",
    "for pos in positiveLex + cosPosLex:\n",
    "    stem_token = PorterStemmer().stem(pos)\n",
    "    stemPosLex.append(stem_token)\n",
    "\n",
    "stemNegLex = []\n",
    "for neg in negativeLex + cosNegLex:\n",
    "    stem_token = PorterStemmer().stem(neg)\n",
    "    stemNegLex.append(stem_token)\n",
    "    \n",
    "lines = []\n",
    "with open('regulationAnnotatedAll.txt') as fp:  \n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        lines.append(line)\n",
    "        if '\\tAffirmative\\n' in line:\n",
    "            word_tokens = word_tokenize(line)\n",
    "            for token in word_tokens:\n",
    "                if PorterStemmer().stem(token) in stemPosLex:\n",
    "                    try:\n",
    "                        aff_dic[PorterStemmer().stem(token)] += 1\n",
    "                    except:\n",
    "                        aff_dic[PorterStemmer().stem(token)] = 1\n",
    "                elif PorterStemmer().stem(token) in stemNegLex:\n",
    "                    try:\n",
    "                        aff_dic[PorterStemmer().stem(token)] += 1\n",
    "                    except:\n",
    "                        aff_dic[PorterStemmer().stem(token)] = 1\n",
    "        if '\\tNegation\\n' in line:\n",
    "            word_tokens = word_tokenize(line)\n",
    "            for token in word_tokens:\n",
    "                if PorterStemmer().stem(token) in stemPosLex:\n",
    "                    try:\n",
    "                        neg_dic[PorterStemmer().stem(token)] += 1\n",
    "                    except:\n",
    "                        neg_dic[PorterStemmer().stem(token)] = 1\n",
    "                elif PorterStemmer().stem(token) in stemNegLex:\n",
    "                    try:\n",
    "                        neg_dic[PorterStemmer().stem(token)] += 1\n",
    "                    except:\n",
    "                        neg_dic[PorterStemmer().stem(token)] = 1\n",
    "        if '\\tNone\\n' in line:\n",
    "            word_tokens = word_tokenize(line)\n",
    "            for token in word_tokens:\n",
    "                if PorterStemmer().stem(token) in stemPosLex:\n",
    "                    try:\n",
    "                        non_dic[PorterStemmer().stem(token)] += 1\n",
    "                    except:\n",
    "                        non_dic[PorterStemmer().stem(token)] = 1\n",
    "                elif PorterStemmer().stem(token) in stemNegLex:\n",
    "                    try:\n",
    "                        non_dic[PorterStemmer().stem(token)] += 1\n",
    "                    except:\n",
    "                        non_dic[PorterStemmer().stem(token)] = 1\n",
    "        line = fp.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activ': 15,\n",
       " 'block': 2,\n",
       " 'elev': 2,\n",
       " 'enhanc': 1,\n",
       " 'increas': 12,\n",
       " 'induc': 11,\n",
       " 'inhibit': 2,\n",
       " 'stimul': 8}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aff_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activ': 9,\n",
       " 'antagonist': 1,\n",
       " 'declin': 1,\n",
       " 'elev': 1,\n",
       " 'increas': 4,\n",
       " 'induc': 2,\n",
       " 'inhibit': 13,\n",
       " 'inhibitor': 2,\n",
       " 'inhibitori': 2,\n",
       " 'stimul': 2,\n",
       " 'suppress': 2}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-stimul': 5,\n",
       " 'activ': 180,\n",
       " 'antagonist': 49,\n",
       " 'block': 5,\n",
       " 'declin': 6,\n",
       " 'down-regul': 20,\n",
       " 'downregul': 3,\n",
       " 'elev': 10,\n",
       " 'enhanc': 11,\n",
       " 'inactiv': 4,\n",
       " 'increas': 96,\n",
       " 'induc': 39,\n",
       " 'inhibit': 27,\n",
       " 'inhibitor': 4,\n",
       " 'inhibitori': 3,\n",
       " 'stimul': 39,\n",
       " 'stimulatori': 4,\n",
       " 'suppress': 7,\n",
       " 'up-regul': 16}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for key in aff_dic:\n",
    "    try:\n",
    "        dic[key] = dic[key] + aff_dic[key]\n",
    "    except:\n",
    "        dic[key] = aff_dic[key]\n",
    "for key in neg_dic:\n",
    "    try:\n",
    "        dic[key] = dic[key] + neg_dic[key]\n",
    "    except:\n",
    "        dic[key] = neg_dic[key]\n",
    "for key in non_dic:\n",
    "    try:\n",
    "        dic[key] = dic[key] + non_dic[key]\n",
    "    except:\n",
    "        dic[key] = non_dic[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block: 28.57142857142857%\n",
      "induc: 21.153846153846153%\n",
      "increas: 10.714285714285714%\n",
      "activ: 7.352941176470589%\n",
      "enhanc: 8.333333333333332%\n",
      "inhibit: 4.761904761904762%\n",
      "stimul: 16.3265306122449%\n",
      "elev: 15.384615384615385%\n",
      "inhibitori: 0%\n",
      "suppress: 0%\n",
      "declin: 0%\n",
      "inhibitor: 0%\n",
      "antagonist: 0%\n",
      "down-regul: 0%\n",
      "-stimul: 0%\n",
      "inactiv: 0%\n",
      "downregul: 0%\n",
      "stimulatori: 0%\n",
      "up-regul: 0%\n"
     ]
    }
   ],
   "source": [
    "for key in dic:\n",
    "    try:\n",
    "        print(key+': '+str(1.0*aff_dic[key]/dic[key]*100)+'%')\n",
    "    except:\n",
    "        print(key+': 0%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block: 0%\n",
      "induc: 3.8461538461538463%\n",
      "increas: 3.571428571428571%\n",
      "activ: 4.411764705882353%\n",
      "enhanc: 0%\n",
      "inhibit: 30.952380952380953%\n",
      "stimul: 4.081632653061225%\n",
      "elev: 7.6923076923076925%\n",
      "inhibitori: 40.0%\n",
      "suppress: 22.22222222222222%\n",
      "declin: 14.285714285714285%\n",
      "inhibitor: 33.33333333333333%\n",
      "antagonist: 2.0%\n",
      "down-regul: 0%\n",
      "-stimul: 0%\n",
      "inactiv: 0%\n",
      "downregul: 0%\n",
      "stimulatori: 0%\n",
      "up-regul: 0%\n"
     ]
    }
   ],
   "source": [
    "for key in dic:\n",
    "    try:\n",
    "        print(key+': '+str(1.0*neg_dic[key]/dic[key]*100)+'%')\n",
    "    except:\n",
    "        print(key+': 0%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block: 71.42857142857143%\n",
      "induc: 75.0%\n",
      "increas: 85.71428571428571%\n",
      "activ: 88.23529411764706%\n",
      "enhanc: 91.66666666666666%\n",
      "inhibit: 64.28571428571429%\n",
      "stimul: 79.59183673469387%\n",
      "elev: 76.92307692307693%\n",
      "inhibitori: 60.0%\n",
      "suppress: 77.77777777777779%\n",
      "declin: 85.71428571428571%\n",
      "inhibitor: 66.66666666666666%\n",
      "antagonist: 98.0%\n",
      "down-regul: 100.0%\n",
      "-stimul: 100.0%\n",
      "inactiv: 100.0%\n",
      "downregul: 100.0%\n",
      "stimulatori: 100.0%\n",
      "up-regul: 100.0%\n"
     ]
    }
   ],
   "source": [
    "for key in dic:\n",
    "    try:\n",
    "        print(key+': '+str(1.0*non_dic[key]/dic[key]*100)+'%')\n",
    "    except:\n",
    "        print(key+': 0%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
